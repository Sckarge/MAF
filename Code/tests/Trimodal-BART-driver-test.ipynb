{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "import gc\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score.rouge_scorer import RougeScorer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'code_mixed_explanation'\n",
    "TEXT_INPUT_PATH = '../../Data/Text/'\n",
    "ACOUSTIC_INPUT_PATH = '../../Data/Audio/'\n",
    "VISUAL_INPUT_PATH = '../../Data/Video/'\n",
    "\n",
    "MODEL_OUTPUT_DIR = '../../models/MAF-TAV-BART/'\n",
    "RESULT_OUTPUT_DIR = '../../results/MAF-TAV-BART/'\n",
    "\n",
    "LOWERCASE_UTTERANCES = False\n",
    "UNFOLDED_DIALOGUE = True\n",
    "\n",
    "if UNFOLDED_DIALOGUE:\n",
    "    SOURCE_COLUMN = 'dialogue'\n",
    "else:\n",
    "    SOURCE_COLUMN_1 = 'target'\n",
    "    SOURCE_COLUMN_2 = 'context'\n",
    "    \n",
    "\n",
    "\n",
    "SOURCE_MAX_LEN = 480\n",
    "TARGET_MAX_LEN = 50\n",
    "MAX_UTTERANCES = 25\n",
    "\n",
    "ACOUSTIC_DIM = 154\n",
    "ACOUSTIC_MAX_LEN = 600\n",
    "\n",
    "VISUAL_DIM = 2048\n",
    "VISUAL_MAX_LEN = 96 \n",
    "\n",
    "BATCH_SIZE = 4\n",
    "MAX_EPOCHS = 60\n",
    "\n",
    "BASE_LEARNING_RATE = 5e-6\n",
    "NEW_LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "NUM_BEAMS = 5\n",
    "EARLY_STOPPING = True\n",
    "NO_REPEAT_NGRAM_SIZE = 3\n",
    "\n",
    "EARLY_STOPPING_THRESHOLD = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function to seed experiment for reproducibility.\n",
    "    If -1 is provided as seed, experiment uses random seed from 0~9999\n",
    "    Args:\n",
    "        seed (int): integer to be used as seed, use -1 to randomly seed experiment\n",
    "    \"\"\"\n",
    "    print(\"Seed: {}\".format(seed))\n",
    "\n",
    "\n",
    "    # These lines below ensure determinism by turning off some optimizations\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    if seed == -1:\n",
    "        seed = random.randint(0, 9999)\n",
    "\n",
    "    # We set all seeds in libraries to our seed\n",
    "    \n",
    "    random.seed(seed) #python built-in\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed) #seed for hash based ops in python\n",
    "    np.random.seed(seed) #numpy random gen\n",
    "    torch.manual_seed(seed) # torch CPU random generator\n",
    "    torch.cuda.manual_seed(seed) # current gpu rand gen\n",
    "    torch.cuda.manual_seed_all(seed) # all gpus rand gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "from transformers.modeling_utils import PreTrainedModel, unwrap_model\n",
    "\n",
    "from transformers import (\n",
    "    BartTokenizerFast,\n",
    "    AdamW\n",
    ")\n",
    "\n",
    "from transformers.models.bart.configuration_bart import BartConfig\n",
    "\n",
    "# from transformers.models.bart.modeling_bart import (\n",
    "#     BartPretrainedModel,\n",
    "#     BartDecoder,\n",
    "#     BartLearnedPositionalEmbedding,\n",
    "#     BartEncoderLayer,\n",
    "#     shift_tokens_right,\n",
    "#     _make_causal_mask,\n",
    "#     _expand_mask \n",
    "# )\n",
    "\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutput,\n",
    "    Seq2SeqLMOutput,\n",
    "    Seq2SeqModelOutput\n",
    ")\n",
    "\n",
    "\n",
    "# from transformer_encoder import TransformerEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCA2\n",
    "Refer to [MCA2 doc](./MCA2_test.ipynb) to understand the workings of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextAwareAttention(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim_model: int,\n",
    "                 dim_context: int,\n",
    "                 dropout_rate: Optional[float]=0.0):\n",
    "        super(ContextAwareAttention, self).__init__()\n",
    "        \n",
    "        self.dim_model = dim_model\n",
    "        self.dim_context = dim_context\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.attention_layer = nn.MultiheadAttention(embed_dim=self.dim_model, \n",
    "                                                     num_heads=1, \n",
    "                                                     dropout=self.dropout_rate, \n",
    "                                                     bias=True,\n",
    "                                                     add_zero_attn=False,\n",
    "                                                     batch_first=True,\n",
    "                                                     device=DEVICE)\n",
    "\n",
    "\n",
    "        self.u_k = nn.Linear(self.dim_context, self.dim_model, bias=False)\n",
    "        self.w1_k = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        self.w2_k = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        \n",
    "        self.u_v = nn.Linear(self.dim_context, self.dim_model, bias=False)\n",
    "        self.w1_v = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        self.w2_v = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                q: torch.Tensor, \n",
    "                k: torch.Tensor,\n",
    "                v: torch.Tensor,\n",
    "                context: Optional[torch.Tensor]=None):\n",
    "        \n",
    "        key_context = self.u_k(context)\n",
    "        value_context = self.u_v(context)\n",
    "\n",
    "        lambda_k = F.sigmoid(self.w1_k(k) + self.w2_k(key_context))\n",
    "        lambda_v = F.sigmoid(self.w1_v(v) + self.w2_v(value_context))\n",
    "\n",
    "        k_cap = (1 - lambda_k) * k + lambda_k * key_context\n",
    "        v_cap = (1 - lambda_v) * v + lambda_v * value_context\n",
    "\n",
    "        attention_output, _ = self.attention_layer(query=q,\n",
    "                                                   key=k_cap,\n",
    "                                                   value=v_cap)\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\n",
    "        'num_beams': NUM_BEAMS,\n",
    "        'max_length': TARGET_MAX_LEN,\n",
    "        'early_stopping': EARLY_STOPPING,\n",
    "        'no_repeat_ngram_size': NO_REPEAT_NGRAM_SIZE\n",
    "    }\n",
    "    \n",
    "    train(model=MODEL,\n",
    "          tokenizer=TOKENIZER,\n",
    "          train_data_loader=train_dataset,\n",
    "          val_data_loader=val_dataset,\n",
    "          test_data_loader=test_dataset,\n",
    "          base_learning_rate=BASE_LEARNING_RATE,\n",
    "          new_learning_rate=NEW_LEARNING_RATE,\n",
    "          weight_decay=WEIGHT_DECAY,\n",
    "          **gen_kwargs)\n",
    "    \n",
    "    print(\"Model Trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
