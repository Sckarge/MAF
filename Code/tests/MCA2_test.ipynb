{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     DEVICE = torch.device(\"cuda\")\n",
    "#     print(\"Using GPU\")\n",
    "# else:\n",
    "#     DEVICE = torch.device(\"cpu\")\n",
    "#     print(\"Using CPU\")\n",
    "DEVICE = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextAwareAttention(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim_model: int,\n",
    "                 dim_context: int,\n",
    "                 dropout_rate: Optional[float]=0.0,\n",
    "                 num_heads: int = 1):\n",
    "        super(ContextAwareAttention, self).__init__()\n",
    "        \n",
    "        self.dim_model = dim_model\n",
    "        self.dim_context = dim_context\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.attention_layer = nn.MultiheadAttention(embed_dim=self.dim_model, \n",
    "                                                    num_heads=num_heads, \n",
    "                                                    dropout=self.dropout_rate, \n",
    "                                                    bias=True,\n",
    "                                                    add_zero_attn=False,\n",
    "                                                    batch_first=True,\n",
    "                                                    device=DEVICE)\n",
    "\n",
    "\n",
    "        self.u_k = nn.Linear(self.dim_context, self.dim_model, bias=False)\n",
    "        self.w1_k = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        self.w2_k = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        \n",
    "        self.u_v = nn.Linear(self.dim_context, self.dim_model, bias=False)\n",
    "        self.w1_v = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        self.w2_v = nn.Linear(self.dim_model, 1, bias=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                q: torch.Tensor, \n",
    "                k: torch.Tensor,\n",
    "                v: torch.Tensor,\n",
    "                context: Optional[torch.Tensor]=None):\n",
    "        \n",
    "        #transformation of context to model dims\n",
    "        key_context = self.u_k(context)\n",
    "        value_context = self.u_v(context)\n",
    "\n",
    "        # Calculation of lambda \n",
    "        lambda_k = F.sigmoid(self.w1_k(k) + self.w2_k(key_context))\n",
    "        lambda_v = F.sigmoid(self.w1_v(v) + self.w2_v(value_context))\n",
    "\n",
    "        # print(f'Value: {lambda_k}\\n Shape:{lambda_k.shape}')\n",
    "        # print(1-lambda_k)\n",
    "\n",
    "        # lambda is a 1 dimensional row matrix, each row is multiplied with the entire row of the other vector\n",
    "        k_cap = (1 - lambda_k) * k + lambda_k * key_context\n",
    "        v_cap = (1 - lambda_v) * v + lambda_v * value_context\n",
    "\n",
    "        attention_output, _ = self.attention_layer(query=q,\n",
    "                                                   key=k_cap,\n",
    "                                                   value=v_cap)\n",
    "        \n",
    "        # print(f'{context.shape=}\\n{key_context.shape=}\\n{value_context.shape=}\\n{lambda_k.shape=}\\n{lambda_v.shape=}\\n{key_context.shape=}\\n{k_cap=}\\n{v_cap}')\n",
    "        return attention_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCA2 = ContextAwareAttention(10,5,0.01,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90336b2f70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_wts = torch.rand(10,10,generator = g)\n",
    "test_context = torch.rand(10,5,generator = g)\n",
    "# print(test_model_wts,'\\n',test_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCA2_op = MCA2.forward(test_model_wts,test_model_wts,test_model_wts,test_context)\n",
    "# MCA2_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_n_1_matrix = torch.rand(2,1)\n",
    "test_wts_2 = torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'{test_wts_2=}\\n{rand_n_1_matrix=}\\n{(rand_n_1_matrix*test_wts_2)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv~",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
